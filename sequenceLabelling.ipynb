{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('words_values_data_raunaq.csv')\n",
    "data=pd.concat([data[data['files']==x] for x in np.unique(data.files) if np.array(data[data['files']==x].labels).sum() > 0],axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>coords</th>\n",
       "      <th>files</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TAX</td>\n",
       "      <td>[1080, 63, 1143, 105]</td>\n",
       "      <td>12222018075543.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INVOICE</td>\n",
       "      <td>[1166, 62, 1323, 102]</td>\n",
       "      <td>12222018075543.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSTIN</td>\n",
       "      <td>[94, 143, 208, 192]</td>\n",
       "      <td>12222018075543.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03AUVPS8413J121</td>\n",
       "      <td>[250, 140, 610, 184]</td>\n",
       "      <td>12222018075543.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORIGINAL</td>\n",
       "      <td>[1891, 47, 2085, 94]</td>\n",
       "      <td>12222018075543.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             words                 coords               files  labels\n",
       "0              TAX  [1080, 63, 1143, 105]  12222018075543.jpg       0\n",
       "1          INVOICE  [1166, 62, 1323, 102]  12222018075543.jpg       0\n",
       "2            GSTIN    [94, 143, 208, 192]  12222018075543.jpg       0\n",
       "3  03AUVPS8413J121   [250, 140, 610, 184]  12222018075543.jpg       0\n",
       "4         ORIGINAL   [1891, 47, 2085, 94]  12222018075543.jpg       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[data[data['files']==x].shape[0] for x in np.unique(data.files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179.24858757062148, 58.58318062103969, 160.5, 84, 401)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(words).mean(),np.array(words).std(),np.median(np.array(words)),np.array(words).min(),np.array(words).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(337,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.array(words)<300)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=np.array([(x,' '.join([str(y) for y in list(data[data['files']==x].words)]),''.join([str(y) for y in list(data[data['files']==x].labels)])) for x in np.unique(data.files)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [x[1] for x in sentence]\n",
    "files= [x[0] for x in sentence]\n",
    "labels = [x[-1] for x in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sen = pd.DataFrame([files,text,labels]).T\n",
    "df_sen.columns=['files','text','labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_sen.text,df_sen.labels, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[X_train, X_val, y_train, y_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dbpath = open('train.pk','wb')\n",
    "pickle.dump(x,dbpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "X_train, X_val, y_train, y_val=pickle.load(open('train.pk','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MOBILE BILL.jpg',\n",
       " 'GSTIN 03AAQFB6165R1ZS TAX INVOICE (Original for Buyer)\\n TIN 03722201169 Phone No: 98140-20241 98100-09439\\n BPR ZIPPERS Manufacturers of: CFC ZIPPER ROLLS\\n F-295, PHASE-VIII, FOCAL POINT, LUDHIANA-141010 (PUNJAB) INDIA. E-mail id bprzippers@gmail.com\\n MIS EXCEL TRADING COMPANY Invoice 204 Dated 30/06/2018\\n 9/952,ANANDPURI COLONY Order No: Dated :\\n NOORWALA ROAD\\n LUDHIANA\\n State PUNJAB G.R. No: Dated: 11\\n GSTIN 03AUWPS7596M1ZC PAN Transport:\\n Ph. No: 9888886346 Email ID: Vehicle No: No.of Pack:\\n P.mark No Weight: 31.000\\n Sr. Description of goods HSN Qnty Per Rate Amount C-GST S-GST I-GST TOTAL\\n No\\n Code Rate Amoun Rate Amount Rate Amoun\\n ZIPPER ROLL\\n 96072000 30.000 350.00 10,500.00 9.00 945.00 9.000 945.00 12,390.00\\n ZIPPER ROLL\\n 96072000 1.000 400.00 400.00 9.00 36.00 9.000 36.00 472.00 Total 31.000 10,900.00 12,862.00 Remarks: 981.00| 981.00\\n Total Taxable Value\\n Total C-GST Amount\\n Total S-GST Amount 10900.00 981.00\\n 981.00 GRAND TOTAL 12,862.00\\n For BPR ZIPPERS Total Value In Words Rs.Twelve Thousand Eight Hundred Sixty Two Only\\n Terms Conditions :\\n 1. Subject to LUDHIANA Jurisdiction Only\\n 2. Goods once sold are not returnable or exchangeable\\n 3. Our responsibility ceases after the goods are removed from our premises.\\n 4. If the bill is not paid within week Interest @24% will be charged from the date of bill.\\n E.& O.E. Authorised Signatory')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_te[9],X_val[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_tr=list(np.unique(df_sen.loc[X_train.index]['files']))\n",
    "f_te=list(np.unique(df_sen.loc[X_val.index]['files']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_test=['12222018090033.jpg',\n",
    " 'rudramotors-sale-2-01.png',\n",
    " 'invoices1-087.png',\n",
    " 'purchasebillstvs-29.png',\n",
    " 'Sale of TVS AGENCY 31.10.1825112018131725_010.jpg',\n",
    " 'Sale of TVS AGENCY 31.10.1825112018131727_013.jpg',\n",
    " 'SN_aggarwal_29Nov.jpg',\n",
    " 'rudramotors-sale-1-09.png',\n",
    " '12222018081345.jpg',\n",
    " '18-Dec-Purchase-12.png',\n",
    " 'Sale of TVS AGENCY 31.10.1825112018131739_033.jpg',\n",
    " 'img34.jpg',\n",
    " '18-Dec-Exp-04.png',\n",
    " 'img26.jpg',\n",
    " '18-Dec-Purchase-07.png',\n",
    " 'PURCHASE OF NATIONAL TECH TRIAL05122018171245_006.jpg',\n",
    " '12222018081237.jpg',\n",
    " 'rudramotors-sale-1-43.png',\n",
    " 'purchasebillstvs-22.png',\n",
    " 'img44.jpg',\n",
    " 'gurjanwal_1Dec.jpg',\n",
    " 'shade_16_nov.jpg',\n",
    " 'img28.jpg',\n",
    " 'invoices1-023.png',\n",
    " 'invoices1-035.png',\n",
    " '12222018085524.jpg',\n",
    " 'Sale of TVS AGENCY 31.10.1825112018131738_032.jpg',\n",
    " '18-Dec-Exp-05.png',\n",
    " 'PURCHASE BILL.jpg',\n",
    " 'rudramotors-sale-1-59.png',\n",
    " 'PURCHASE OF NATIONAL TECH TRIAL05122018171243_001.jpg',\n",
    " 'PURCHASE OF NATIONAL TECH TRIAL05122018171246_007.jpg',\n",
    " 'purchasebills-23.png',\n",
    " 'Purchase of TVS AGENCY 31.10.1825112018114910_005.jpg',\n",
    " 'Purchase of TVS AGENCY 31.10.1825112018114908_001.jpg',\n",
    " 'invoices1-031.png',\n",
    " 'purchasebills-20.png',\n",
    " 'Purchase of TVS AGENCY 31.10.1825112018114911_007.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rudramotors-sale-1-09.png']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in o_test if x not in f_tr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Token classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn\n",
    "# import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM,BertForTokenClassification\n",
    "\n",
    "import pytorch_pretrained_bert as _bert\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def flatten(list_of_lists):\n",
    "    for list in list_of_lists:\n",
    "        for item in list:\n",
    "            yield item\n",
    "\n",
    "\n",
    "\n",
    "_device = torch.device(\"cuda\")\n",
    "class Bert():\n",
    "\n",
    "    MASK = '[MASK]'\n",
    "    CLS = \"[CLS]\"\n",
    "    SEP = \"[SEP]\"\n",
    "\n",
    "#     supported_langs = set(lines(\n",
    "#         Path(__file__).parent / \"data\" / \"bert_langs.wiki\"))\n",
    "\n",
    "    def __init__(self, model, model_name, device=None, half_precision=False):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.device = device or _device\n",
    "        do_lower_case = \"uncased\" in model_name\n",
    "        self.tokenizer = _bert.BertTokenizer.from_pretrained(\n",
    "            self.model_name, do_lower_case=do_lower_case)\n",
    "        maybe_model_wrapper = model.from_pretrained(model_name).to(\n",
    "            device=self.device)\n",
    "        try:\n",
    "            self.model = maybe_model_wrapper.bert\n",
    "        except AttributeError:\n",
    "            self.model = maybe_model_wrapper\n",
    "        if half_precision:\n",
    "            self.model.half()\n",
    "        self.max_len = \\\n",
    "            self.model.embeddings.position_embeddings.weight.size(0)\n",
    "        self.dim = self.model.embeddings.position_embeddings.weight.size(1)\n",
    "\n",
    "    def tokenize(self, text, masked_idxs=None):\n",
    "        tokenized_text = self.tokenizer.tokenize(text)\n",
    "        if masked_idxs is not None:\n",
    "            for idx in masked_idxs:\n",
    "                tokenized_text[idx] = self.MASK\n",
    "        # prepend [CLS] and append [SEP]\n",
    "        # see https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_classifier.py#L195  # NOQA\n",
    "        tokenized = [self.CLS] + tokenized_text + [self.SEP]\n",
    "        return tokenized\n",
    "\n",
    "    def tokenize_to_ids(self, text, masked_idxs=None, pad=True):\n",
    "        tokens = self.tokenize(text, masked_idxs)\n",
    "        return self.convert_tokens_to_ids(tokens, pad=pad)\n",
    "\n",
    "    def convert_tokens_to_ids(self, tokens, pad=True):\n",
    "        token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        ids = torch.tensor([token_ids]).to(device=self.device)\n",
    "        assert ids.size(1) < self.max_len\n",
    "        if pad:\n",
    "            padded_ids = torch.zeros(1, self.max_len).to(ids)\n",
    "            padded_ids[0, :ids.size(1)] = ids\n",
    "            mask = torch.zeros(1, self.max_len).to(ids)\n",
    "            mask[0, :ids.size(1)] = 1\n",
    "            return padded_ids, mask\n",
    "        else:\n",
    "            return ids\n",
    "\n",
    "    def subword_tokenize(self, tokens):\n",
    "        \"\"\"Segment each token into subwords while keeping track of\n",
    "        token boundaries.\n",
    "        Parameters\n",
    "        ----------\n",
    "        tokens: A sequence of strings, representing input tokens.\n",
    "        Returns\n",
    "        -------\n",
    "        A tuple consisting of:\n",
    "            - A list of subwords, flanked by the special symbols required\n",
    "                by Bert (CLS and SEP).\n",
    "            - An array of indices into the list of subwords, indicating\n",
    "                that the corresponding subword is the start of a new\n",
    "                token. For example, [1, 3, 4, 7] means that the subwords\n",
    "                1, 3, 4, 7 are token starts, while all other subwords\n",
    "                (0, 2, 5, 6, 8...) are in or at the end of tokens.\n",
    "                This list allows selecting Bert hidden states that\n",
    "                represent tokens, which is necessary in sequence\n",
    "                labeling.\n",
    "        \"\"\"\n",
    "        subwords = list(map(self.tokenizer.tokenize, tokens))\n",
    "        subword_lengths = list(map(len, subwords))\n",
    "        subwords = [self.CLS] + list(flatten(subwords)) + [self.SEP]\n",
    "        token_start_idxs = 1 + np.cumsum([0] + subword_lengths[:-1])\n",
    "        return subwords, token_start_idxs\n",
    "\n",
    "    def subword_tokenize_to_ids(self, tokens):\n",
    "        \"\"\"Segment each token into subwords while keeping track of\n",
    "        token boundaries and convert subwords into IDs.\n",
    "        Parameters\n",
    "        ----------\n",
    "        tokens: A sequence of strings, representing input tokens.\n",
    "        Returns\n",
    "        -------\n",
    "        A tuple consisting of:\n",
    "            - A list of subword IDs, including IDs of the special\n",
    "                symbols (CLS and SEP) required by Bert.\n",
    "            - A mask indicating padding tokens.\n",
    "            - An array of indices into the list of subwords. See\n",
    "                doc of subword_tokenize.\n",
    "        \"\"\"\n",
    "        subwords, token_start_idxs = self.subword_tokenize(tokens)\n",
    "        subword_ids, mask = self.convert_tokens_to_ids(subwords)\n",
    "        token_starts = torch.zeros(1, self.max_len).to(subword_ids)\n",
    "        token_starts[0, token_start_idxs] = 1\n",
    "        return subword_ids, mask, token_starts\n",
    "\n",
    "    def segment_ids(self, segment1_len, segment2_len):\n",
    "        ids = [0] * segment1_len + [1] * segment2_len\n",
    "        return torch.tensor([ids]).to(device=self.device)\n",
    "\n",
    "    @staticmethod\n",
    "    def Model(model_name, **kwargs):\n",
    "        return Bert(_bert.BertModel, model_name, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def ForMaskedLM(model_name, **kwargs):\n",
    "        return Bert(_bert.BertForMaskedLM, model_name, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def ForSequenceClassification(model_name, **kwargs):\n",
    "        return Bert(\n",
    "            _bert.BertForSequenceClassification, model_name, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def ForNextSentencePrediction(model_name, **kwargs):\n",
    "        return Bert(_bert.BertForNextSentencePrediction, model_name, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def ForForPreTraining(model_name, **kwargs):\n",
    "        return Bert(_bert.BertForPreTraining, model_name, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def ForForQuestionAnswering(model_name, **kwargs):\n",
    "        return Bert(_bert.BertForQuestionAnswering, model_name, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = Bert(BertModel,'bert-base-cased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(np.array([len(x.split(' ')) for x in X_train]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(X_train)[41].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=list(X_train)[41]\n",
    "featurized_sentences = []\n",
    "\n",
    "tokens=tokens.split(' ')\n",
    "\n",
    "features = {}\n",
    "\n",
    "features[\"bert_ids\"], features[\"bert_mask\"], features[\"bert_token_starts\"] = bert.subword_tokenize_to_ids(tokens)\n",
    "featurized_sentences.append(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurized_sentences = []\n",
    "for j,tokens in enumerate(X_train):\n",
    "    tokens=tokens.split(' ')\n",
    "    try:\n",
    "        features = {}\n",
    "\n",
    "        features[\"bert_ids\"], features[\"bert_mask\"], features[\"bert_token_starts\"] = bert.subword_tokenize_to_ids(tokens)\n",
    "        featurized_sentences.append(features)\n",
    "    except:\n",
    "        featurized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(featurized_sentences_batch):\n",
    "    bert_batch = [torch.cat([features[key] for features in featurized_sentences], dim=0) for key in (\"bert_ids\", \"bert_mask\", \"bert_token_starts\")]\n",
    "    return bert_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceTagger(torch.nn.Module):\n",
    "     def __init__(self, data_parallel=True):\n",
    "            bert = BertModel.from_pretrained(\"bert-base-cased\").to(device=torch.device(\"cuda\"))\n",
    "            self.bert = bert\n",
    "            bert_dim = 786 # (or get the dim from BertEmbeddings)\n",
    "            n_labels = 5  # need to set this for your task\n",
    "            self.out = torch.nn.Linear(bert_dim, n_labels)\n",
    "            #...  # droput, log_softmax...\n",
    "    \n",
    "     def forward(self, bert_batch, true_labels):\n",
    "            bert_ids, bert_mask, bert_token_starts = bert_batch\n",
    "            # truncate to longest sequence length in batch (usually much smaller than 512) to save GPU RAM\n",
    "            max_length = (bert_mask != 0).max(0)[0].nonzero()[-1].item()\n",
    "            if max_length < bert_ids.shape[1]:\n",
    "                  bert_ids = bert_ids[:, :max_length]\n",
    "                  bert_mask = bert_mask[:, :max_length]\n",
    "\n",
    "            segment_ids = torch.zeros_like(bert_mask)  # dummy segment IDs, since we only have one sentence\n",
    "            bert_last_layer = self.bert(bert_ids, segment_ids)[0][-1]\n",
    "            # select the states representing each token start, for each instance in the batch\n",
    "            bert_token_reprs = [\n",
    "                   layer[starts.nonzero().squeeze(1)]\n",
    "                   for layer, starts in zip(bert_last_layer, bert_token_starts)]\n",
    "            # need to pad because sentence length varies\n",
    "            padded_bert_token_reprs = pad_sequence(\n",
    "                   bert_token_reprs, batch_first=True, padding_value=-1)\n",
    "            # output/classification layer: input bert states and get log probabilities for cross entropy loss\n",
    "            pred_logits = self.log_softmax(self.out(self.dropout(padded_bert_token_reprs)))\n",
    "            mask = true_labels != -1  # I did set label = -1 for all padding tokens somewhere else\n",
    "            loss = cross_entropy(pred_logits, true_labels)\n",
    "            # average/reduce the loss according to the actual number of of predictions (i.e. one prediction per token).\n",
    "            loss /= mask.float().sum()\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collate\n",
    "bert_batch=collate_fn(featurized_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_ids, bert_mask, bert_token_starts = bert_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-978a5530c144>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbert_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "bert_batch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = (bert_mask != 0).max(0)[0].nonzero()[-1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227, 512)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length,bert_ids.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "if max_length < bert_ids.shape[1]:\n",
    "                  bert_ids = bert_ids[:, :max_length]\n",
    "                  bert_mask = bert_mask[:, :max_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_ids = torch.zeros_like(bert_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=BertModel.from_pretrained(\"bert-base-cased\").to(device=torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_last_layer = model(bert_ids, segment_ids)[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 416, 768])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_last_layer.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_token_reprs = [\n",
    "                   layer[starts.nonzero().squeeze(1)]\n",
    "                   for layer, starts in zip(bert_last_layer, bert_token_starts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "padded_bert_token_reprs = pad_sequence(\n",
    "                   bert_token_reprs, batch_first=True, padding_value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.nn.Linear(768, 5).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "true_labels=torch.tensor([int(x) for x in list(list(y_train)[40])]).long()\n",
    "cross_entropy = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raghu/venv/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# output/classification layer: input bert states and get log probabilities for cross entropy loss\n",
    "pred_logits = F.log_softmax(out(padded_bert_token_reprs))\n",
    "mask = true_labels != -1  # I did set label = -1 for all padding tokens somewhere else\n",
    "loss = cross_entropy(pred_logits.cpu().view([pred_logits.cpu().size()[1],5]), true_labels)\n",
    "# average/reduce the loss according to the actual number of of predictions (i.e. one prediction per token).\n",
    "# loss /= mask.float().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 84, 768])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_bert_token_reprs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([84, 5])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_logits.cpu().view([84,5]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_logits.cpu().size()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(84.)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.float().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6094, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
