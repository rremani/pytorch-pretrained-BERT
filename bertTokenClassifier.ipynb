{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raghu/venv/lib/python3.6/site-packages/ipykernel_launcher.py:76: DeprecationWarning: Flags not at the start of the expression '(2[01]\\\\d{2}|19\\\\d{2})' (truncated)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "money_re = re.compile(r'(?i)^((inr|\\(?r(s\\.?\\)?)?|\\$)[ ]{0,3})?((\\d{1,2}[,])(\\d{2}[,])*)*\\d{3}(\\.\\d{2})?(\\/-)?(([ ]{0,3}inr|rs\\.?|))?$')\n",
    "number_re = re.compile(r'^-?[0-9]+([.,][0-9]+)*$')\n",
    "phone_re = re.compile(r'^(((((\\([0-9]{3}\\))|([0-9]{3}))-?)[0-9]{3}-?)|([0-9]{3}-))[0-9]{4}$')\n",
    "email_re = re.compile(r'^.+@.+\\.[a-z]+$')\n",
    "gst_re = re.compile(r'\\d{2}[A-Z]{5}\\d{4}[A-Z]{1}\\d[A-Z0-9]{1}[A-Z\\d]{1}')\n",
    "\n",
    "pattern_date_1 = (\n",
    "    \"(2[01]\\d{2}|19\\d{2})[ ]?[- ///.][ ]?(0?[1-9]|1[012])\"\n",
    "    \"[ ]?[- ///.][ ]?(3[01]|[012]?\\d)\"\n",
    ")\n",
    "\n",
    "# Examples:\n",
    "# 2017-11-30\n",
    "\n",
    "######################\n",
    "pattern_date_2 = (\n",
    "    \"(3[01]|[012]?\\d)[ ]?[-][ ]?(0?[1-9]|1[012])\"\n",
    "    \"[ ]?[-][ ]?(2[01]\\d{2}|19\\d{2})\"\n",
    ")\n",
    "\n",
    "# Examples:\n",
    "# 29-01-2017\n",
    "# 05-10-2017\n",
    "\n",
    "######################\n",
    "pattern_date_3 = (\n",
    "    \"(3[01]|[012]?\\d)[ ]?[//][ ]?(0?[1-9]|1[012])\"\n",
    "    \"[ ]?[//][ ]?(2[01]\\d{2}|19\\d{2})\"\n",
    ")\n",
    "# 11/01/2018\n",
    "\n",
    "######################\n",
    "pattern_date_4 = (\n",
    "    \"(3[01]|[012]?\\d)[ ]?[/.][ ]?(0?[1-9]|1[012])\"\n",
    "    \"[ ]?[/.][ ]?(2[01]\\d{2}|19\\d{2})\"\n",
    ")\n",
    "# 31.08.2017\n",
    "\n",
    "#####################\n",
    "pattern_date_5= (\n",
    "    \"(?i)(3[01]|[012]?\\d)(th|nd|st)?[ ]?[-][ ]?\"\n",
    "    \"(Jan(uary)?|Feb(ruary)?|Mar(ch)?|Apr(il)?|May|Jun(e)?|Jul(y)?|Aug(ust)?\"\n",
    "    \"|Sep(tember)?|Oct(ober)?|Nov(ember)?|Dec(ember)?)\"\n",
    "    \"[ ]?[-][ ]?\\d{2}(\\d{2})?\"\n",
    ")\n",
    "\n",
    "# Examples:\n",
    "# 21-SEP-19\n",
    "# 07-Nov-2017\n",
    "# 7-Nov-2017\n",
    "# 26-Dec-2017\n",
    "\n",
    "######################\n",
    "pattern_date_6= (\n",
    "    \"(?i)(3[01]|[012]?\\d)(th|nd|st)?[ ]?[ ,][ ]?\"\n",
    "    \"(Jan(uary)?|Feb(ruary)?|Mar(ch)?|Apr(il)?|May|Jun(e)?|Jul(y)?|Aug(ust)?\"\n",
    "    \"|Sep(tember)?|Oct(ober)?|Nov(ember)?|Dec(ember)?)\"\n",
    "    \"[ ]?[ ,'][ ]?\\d{2}(\\d{2})?\"\n",
    ")\n",
    "# 06 Dec 2017\n",
    "# 5 Jan 2018\n",
    "# 24 February 2018\n",
    "# 28 Feb 2018\n",
    "# 28 February,2018\n",
    "# 18th Aug'17\n",
    "# 09 Nov 2017\n",
    "\n",
    "########################\n",
    "pattern_date_7 = (\n",
    "    \"(?i)(Jan(uary)?|Feb(ruary)?|Mar(ch)?|Apr(il)?|May|Jun(e)?\"\n",
    "    \"|Jul(y)?|Aug(ust)?|Sep(tember)?|Oct(ober)?|Nov(ember)?|Dec(ember)?)\"\n",
    "    \"[- ][0123]?\\d(th|nd|st)?[- ,'][ ]?\\d{2}(\\d{2})?\"\n",
    ")\n",
    "date_re = re.compile('|'.join([pattern_date_1, pattern_date_2, pattern_date_3, \\\n",
    "pattern_date_4, pattern_date_5, pattern_date_6, pattern_date_7])\n",
    ")\n",
    "abbrev_dict = {\n",
    "    \"#\": \"number\",\n",
    "    \"acct\": \"account\",\n",
    "    \"amt\":  \"amount\",\n",
    "    \"cnt\":  \"count\",\n",
    "    \"cust\": \"customer\",\n",
    "    \"dept\": \"department\",\n",
    "    \"no.\":  \"number\",\n",
    "    \"no\":   \"number\",\n",
    "    \"num\":  \"number\",\n",
    "    \"ord\": \"order\",\n",
    "    \"pcs\": \"pieces\",\n",
    "    \"qty\": \"quantity\",\n",
    "    \"ref\": \"reference\",\n",
    "    \"seq\": \"sequence\",\n",
    "    \"shp\": \"ship\",\n",
    "    \"tel\": \"telephone\",\n",
    "    \"tkt\": \"ticket\"\n",
    "}\n",
    "def get_type(words):\n",
    "    # default type is text\n",
    "#     word_type = \"text\"\n",
    "    # try parsing as date\n",
    "    if money_re.match(words):\n",
    "        words = \"money\"\n",
    "    elif number_re.match(words):\n",
    "        words = \"number\"\n",
    "    elif date_re.match(words):\n",
    "        words = \"date\"\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "X_train, X_val, y_train, y_val=pickle.load(open('train.pk','rb'))\n",
    "X_train,X_val, y_train, y_val=list(X_train), list(X_val), list(y_train), list(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Since the model can't take more than 512 tokens for a particular sentence after word peice tokenizer\n",
    " # We can further divide the sentences into 50 words length sentences to fit into memory & can be used by Bert model\n",
    " def divide_chunks(l, n): \n",
    "    # looping till length l \n",
    "    for i in range(0, len(l), n):  \n",
    "        yield l[i:i + n]\n",
    " \n",
    "\n",
    " def chunks(x,l,n=84):\n",
    "    text = x.split(' ')\n",
    "    labels = list(l)\n",
    "    length = len(text)\n",
    "    if length > n:\n",
    "        ntext = list(divide_chunks(text,n))\n",
    "        nlabels=list(divide_chunks(labels,n))\n",
    "        return ntext,nlabels\n",
    "    else:\n",
    "        ntext = text\n",
    "        nlabels=labels\n",
    "        return ntext,nlabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "XT,YT=[],[]\n",
    "for i in zip(X_val,y_val):\n",
    "    xt2,yt2=i\n",
    "    xt,yt=chunks(xt2,yt2,n=50)\n",
    "    for j in zip(xt,yt):\n",
    "        xt1,yt1=j\n",
    "        \n",
    "        XT.append([get_type(x) for x in xt1])\n",
    "\n",
    "        YT.append(yt1)\n",
    "XVAL=XT\n",
    "YVAL=YT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "XT,YT=[],[]\n",
    "for i in zip(X_train,y_train):\n",
    "    xt2,yt2=i\n",
    "    xt,yt=chunks(xt2,yt2,n=50)\n",
    "    for j in zip(xt,yt):\n",
    "        xt1,yt1=j\n",
    "        \n",
    "        XT.append([get_type(x) for x in xt1])\n",
    "\n",
    "        YT.append(yt1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['of',\n",
       " 'Goods',\n",
       " 'HSN/SAC',\n",
       " 'Quantity',\n",
       " 'Rate',\n",
       " 'per',\n",
       " 'Disc.',\n",
       " 'Amount',\n",
       " 'No.',\n",
       " 'ZIPPER',\n",
       " 'ROLL',\n",
       " 'HSN:',\n",
       " 'number',\n",
       " 'number',\n",
       " 'number',\n",
       " 'ROLL',\n",
       " 'money',\n",
       " 'ROLL',\n",
       " 'money',\n",
       " 'CGST',\n",
       " 'OUTPUT\\n',\n",
       " 'SGST',\n",
       " 'OUTPUT\\n',\n",
       " 'ROUND',\n",
       " 'OFF',\n",
       " 'money',\n",
       " 'money',\n",
       " '(-)0.28',\n",
       " 'Less',\n",
       " 'Total\\n',\n",
       " 'number',\n",
       " 'ROLL',\n",
       " 'money',\n",
       " 'Amount',\n",
       " 'Chargeable',\n",
       " '(in',\n",
       " 'words)',\n",
       " 'E.',\n",
       " 'O.E\\n',\n",
       " 'INR',\n",
       " 'Sixty',\n",
       " 'Eight',\n",
       " 'Thousand',\n",
       " 'Six',\n",
       " 'Hundred',\n",
       " 'Seventy',\n",
       " 'One',\n",
       " 'Only\\n',\n",
       " 'HSN/SAC\\n',\n",
       " 'Taxable']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XVAL[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define pre-trained tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn\n",
    "# import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM,BertForTokenClassification\n",
    "\n",
    "import pytorch_pretrained_bert as _bert\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def flatten(list_of_lists):\n",
    "    for list in list_of_lists:\n",
    "        for item in list:\n",
    "            yield item\n",
    "\n",
    "\n",
    "\n",
    "_device = torch.device(\"cuda\")\n",
    "class Bert():\n",
    "\n",
    "    MASK = '[MASK]'\n",
    "    CLS = \"[CLS]\"\n",
    "    SEP = \"[SEP]\"\n",
    "\n",
    "#     supported_langs = set(lines(\n",
    "#         Path(__file__).parent / \"data\" / \"bert_langs.wiki\"))\n",
    "\n",
    "    def __init__(self, model, model_name, device=None, half_precision=False):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.device = device or _device\n",
    "        do_lower_case = \"uncased\" in model_name\n",
    "        self.tokenizer = _bert.BertTokenizer.from_pretrained(\n",
    "            self.model_name, do_lower_case=do_lower_case)\n",
    "        maybe_model_wrapper = model.from_pretrained(model_name).to(\n",
    "            device=self.device)\n",
    "        try:\n",
    "            self.model = maybe_model_wrapper.bert\n",
    "        except AttributeError:\n",
    "            self.model = maybe_model_wrapper\n",
    "        if half_precision:\n",
    "            self.model.half()\n",
    "        self.max_len = \\\n",
    "            self.model.embeddings.position_embeddings.weight.size(0)\n",
    "        self.dim = self.model.embeddings.position_embeddings.weight.size(1)\n",
    "\n",
    "    def tokenize(self, text, masked_idxs=None):\n",
    "        tokenized_text = self.tokenizer.tokenize(text)\n",
    "        if masked_idxs is not None:\n",
    "            for idx in masked_idxs:\n",
    "                tokenized_text[idx] = self.MASK\n",
    "        # prepend [CLS] and append [SEP]\n",
    "        # see https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_classifier.py#L195  # NOQA\n",
    "        tokenized = [self.CLS] + tokenized_text + [self.SEP]\n",
    "        return tokenized\n",
    "\n",
    "    def tokenize_to_ids(self, text, masked_idxs=None, pad=True):\n",
    "        tokens = self.tokenize(text, masked_idxs)\n",
    "        return self.convert_tokens_to_ids(tokens, pad=pad)\n",
    "\n",
    "    def convert_tokens_to_ids(self, tokens, pad=True):\n",
    "        token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        ids = torch.tensor([token_ids]).to(device=self.device)\n",
    "        assert ids.size(1) < self.max_len\n",
    "        if pad:\n",
    "            padded_ids = torch.zeros(1, self.max_len).to(ids)\n",
    "            padded_ids[0, :ids.size(1)] = ids\n",
    "            mask = torch.zeros(1, self.max_len).to(ids)\n",
    "            mask[0, :ids.size(1)] = 1\n",
    "            return padded_ids, mask\n",
    "        else:\n",
    "            return ids\n",
    "\n",
    "    def subword_tokenize(self, tokens):\n",
    "        \"\"\"Segment each token into subwords while keeping track of\n",
    "        token boundaries.\n",
    "        Parameters\n",
    "        ----------\n",
    "        tokens: A sequence of strings, representing input tokens.\n",
    "        Returns\n",
    "        -------\n",
    "        A tuple consisting of:\n",
    "            - A list of subwords, flanked by the special symbols required\n",
    "                by Bert (CLS and SEP).\n",
    "            - An array of indices into the list of subwords, indicating\n",
    "                that the corresponding subword is the start of a new\n",
    "                token. For example, [1, 3, 4, 7] means that the subwords\n",
    "                1, 3, 4, 7 are token starts, while all other subwords\n",
    "                (0, 2, 5, 6, 8...) are in or at the end of tokens.\n",
    "                This list allows selecting Bert hidden states that\n",
    "                represent tokens, which is necessary in sequence\n",
    "                labeling.\n",
    "        \"\"\"\n",
    "        subwords = list(map(self.tokenizer.tokenize, tokens))\n",
    "        subword_lengths = list(map(len, subwords))\n",
    "        subwords = [self.CLS] + list(flatten(subwords)) + [self.SEP]\n",
    "        token_start_idxs = 1 + np.cumsum([0] + subword_lengths[:-1])\n",
    "        return subwords, token_start_idxs\n",
    "\n",
    "    def subword_tokenize_to_ids(self, tokens):\n",
    "        \"\"\"Segment each token into subwords while keeping track of\n",
    "        token boundaries and convert subwords into IDs.\n",
    "        Parameters\n",
    "        ----------\n",
    "        tokens: A sequence of strings, representing input tokens.\n",
    "        Returns\n",
    "        -------\n",
    "        A tuple consisting of:\n",
    "            - A list of subword IDs, including IDs of the special\n",
    "                symbols (CLS and SEP) required by Bert.\n",
    "            - A mask indicating padding tokens.\n",
    "            - An array of indices into the list of subwords. See\n",
    "                doc of subword_tokenize.\n",
    "        \"\"\"\n",
    "        subwords, token_start_idxs = self.subword_tokenize(tokens)\n",
    "        subword_ids, mask = self.convert_tokens_to_ids(subwords)\n",
    "        token_starts = torch.zeros(1, self.max_len).to(subword_ids)\n",
    "        token_starts[0, token_start_idxs] = 1\n",
    "        return subword_ids, mask, token_starts\n",
    "\n",
    "    def segment_ids(self, segment1_len, segment2_len):\n",
    "        ids = [0] * segment1_len + [1] * segment2_len\n",
    "        return torch.tensor([ids]).to(device=self.device)\n",
    "\n",
    "    @staticmethod\n",
    "    def Model(model_name, **kwargs):\n",
    "        return Bert(_bert.BertModel, model_name, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def ForMaskedLM(model_name, **kwargs):\n",
    "        return Bert(_bert.BertForMaskedLM, model_name, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def ForSequenceClassification(model_name, **kwargs):\n",
    "        return Bert(\n",
    "            _bert.BertForSequenceClassification, model_name, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def ForNextSentencePrediction(model_name, **kwargs):\n",
    "        return Bert(_bert.BertForNextSentencePrediction, model_name, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def ForForPreTraining(model_name, **kwargs):\n",
    "        return Bert(_bert.BertForPreTraining, model_name, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def ForForQuestionAnswering(model_name, **kwargs):\n",
    "        return Bert(_bert.BertForQuestionAnswering, model_name, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = Bert(BertModel,'bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_features(tokens):\n",
    "    featurized_sentences=[]\n",
    "    for i in tokens:\n",
    "        features = {}\n",
    "        features[\"bert_ids\"], features[\"bert_mask\"], features[\"bert_token_starts\"] = bert.subword_tokenize_to_ids(i)\n",
    "        featurized_sentences.append(features)\n",
    "    bert_batch = [torch.cat([features[key] for features in featurized_sentences], dim=0) for key in (\"bert_ids\", \"bert_mask\", \"bert_token_starts\")]\n",
    "    return bert_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_feature = bert_features(XT)\n",
    "bert_feature_val = bert_features(XVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "cc=compute_class_weight('balanced',[0,1,2,3,4],[int(y) for x in YT for y in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definintion & Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle as pk\n",
    "# from err import model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "from sklearn.metrics import confusion_matrix, f1_score,classification_report\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM,BertForTokenClassification\n",
    "\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained(\"bert-base-cased\").to(device=torch.device(\"cuda\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceTagger(torch.nn.Module):\n",
    "     def __init__(self):\n",
    "            super(SequenceTagger, self).__init__()\n",
    "            self.bert = model\n",
    "            bert_dim = 768 # (or get the dim from BertEmbeddings)\n",
    "            n_labels = 5  # need to set this for your task\n",
    "            self.out = torch.nn.Linear(bert_dim, n_labels)\n",
    "    \n",
    "     def forward(self, bert_batch):\n",
    "#             import pdb;pdb.set_trace()\n",
    "            bert_ids, bert_mask, bert_token_starts = bert_batch\n",
    "            \n",
    "            # truncate to longest sequence length in batch (usually much smaller than 512) to save GPU RAM\n",
    "            max_length = (bert_mask != 0).max(0)[0].nonzero()[-1].item()\n",
    "            if max_length < bert_ids.shape[1]:\n",
    "                    bert_ids = bert_ids[:, :max_length]\n",
    "                    bert_mask = bert_mask[:, :max_length]\n",
    "\n",
    "            segment_ids = torch.zeros_like(bert_mask)  # dummy segment IDs, since we only have one sentence\n",
    "            bert_last_layer = self.bert(bert_ids, segment_ids)[0][-1]\n",
    "            # select the states representing each token start, for each instance in the batch\n",
    "            bert_token_reprs = [\n",
    "                   layer[starts.nonzero().squeeze(1)]\n",
    "                   for layer, starts in zip(bert_last_layer, bert_token_starts)]\n",
    "            # need to pad because sentence length varies\n",
    "            padded_bert_token_reprs = pad_sequence(\n",
    "                   bert_token_reprs, batch_first=True, padding_value=-1)\n",
    "            # output/classification layer: input bert states and get log probabilities for cross entropy loss\n",
    "            pred_logits = self.out(padded_bert_token_reprs)\n",
    "\n",
    "            return pred_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "encoder = SequenceTagger().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  1e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5868\n",
      "           1       0.92      0.94      0.93        36\n",
      "           2       0.95      0.92      0.93        38\n",
      "           3       0.98      0.90      0.94       131\n",
      "           4       1.00      0.97      0.99        37\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      6110\n",
      "   macro avg       0.97      0.95      0.96      6110\n",
      "weighted avg       1.00      1.00      1.00      6110\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5868\n",
      "           1       0.92      0.94      0.93        36\n",
      "           2       0.95      0.92      0.93        38\n",
      "           3       0.98      0.90      0.94       131\n",
      "           4       1.00      0.97      0.99        37\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      6110\n",
      "   macro avg       0.97      0.95      0.96      6110\n",
      "weighted avg       1.00      1.00      1.00      6110\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5868\n",
      "           1       0.92      0.94      0.93        36\n",
      "           2       0.95      0.92      0.93        38\n",
      "           3       0.98      0.90      0.94       131\n",
      "           4       1.00      0.97      0.99        37\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      6110\n",
      "   macro avg       0.97      0.95      0.96      6110\n",
      "weighted avg       1.00      1.00      1.00      6110\n",
      "\n",
      "Epoch:  0  Loss:  tensor(0.0060, device='cuda:0')   F1 Test Score 0.957070205967657   F1 Train Score 0.9853541953678263\n",
      "Learning rate:  1e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5868\n",
      "           1       0.91      0.89      0.90        36\n",
      "           2       0.97      0.92      0.95        38\n",
      "           3       0.98      0.92      0.94       131\n",
      "           4       1.00      0.95      0.97        37\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      6110\n",
      "   macro avg       0.97      0.93      0.95      6110\n",
      "weighted avg       1.00      1.00      1.00      6110\n",
      "\n",
      "Epoch:  1  Loss:  tensor(0.0037, device='cuda:0')   F1 Test Score 0.9524320881430999   F1 Train Score 0.9888070507191813\n",
      "Learning rate:  1e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5868\n",
      "           1       0.92      0.92      0.92        36\n",
      "           2       0.95      0.92      0.93        38\n",
      "           3       0.95      0.95      0.95       131\n",
      "           4       0.97      0.97      0.97        37\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      6110\n",
      "   macro avg       0.96      0.95      0.95      6110\n",
      "weighted avg       1.00      1.00      1.00      6110\n",
      "\n",
      "Epoch:  2  Loss:  tensor(0.0042, device='cuda:0')   F1 Test Score 0.9541899031480761   F1 Train Score 0.9819649596009672\n",
      "Learning rate:  1e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5868\n",
      "           1       0.90      0.97      0.93        36\n",
      "           2       0.90      0.92      0.91        38\n",
      "           3       0.96      0.93      0.95       131\n",
      "           4       0.97      0.97      0.97        37\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      6110\n",
      "   macro avg       0.95      0.96      0.95      6110\n",
      "weighted avg       1.00      1.00      1.00      6110\n",
      "\n",
      "Epoch:  3  Loss:  tensor(0.0040, device='cuda:0')   F1 Test Score 0.9517495656203032   F1 Train Score 0.9890194118194533\n",
      "Learning rate:  1e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5868\n",
      "           1       0.94      0.92      0.93        36\n",
      "           2       0.92      0.92      0.92        38\n",
      "           3       0.94      0.92      0.93       131\n",
      "           4       0.97      0.95      0.96        37\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      6110\n",
      "   macro avg       0.95      0.94      0.95      6110\n",
      "weighted avg       0.99      0.99      0.99      6110\n",
      "\n",
      "Epoch:  4  Loss:  tensor(0.0035, device='cuda:0')   F1 Test Score 0.9466728938221441   F1 Train Score 0.9900203088229185\n",
      "Learning rate:  1e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5868\n",
      "           1       0.91      0.89      0.90        36\n",
      "           2       0.92      0.92      0.92        38\n",
      "           3       0.99      0.90      0.94       131\n",
      "           4       0.97      0.97      0.97        37\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      6110\n",
      "   macro avg       0.96      0.94      0.95      6110\n",
      "weighted avg       1.00      1.00      1.00      6110\n",
      "\n",
      "Epoch:  5  Loss:  tensor(0.0030, device='cuda:0')   F1 Test Score 0.9474271974670943   F1 Train Score 0.9903212337834786\n",
      "Learning rate:  1e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5868\n",
      "           1       0.94      0.89      0.91        36\n",
      "           2       0.95      0.92      0.93        38\n",
      "           3       0.99      0.92      0.96       131\n",
      "           4       1.00      0.97      0.99        37\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      6110\n",
      "   macro avg       0.98      0.94      0.96      6110\n",
      "weighted avg       1.00      1.00      1.00      6110\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5868\n",
      "           1       0.94      0.89      0.91        36\n",
      "           2       0.95      0.92      0.93        38\n",
      "           3       0.99      0.92      0.96       131\n",
      "           4       1.00      0.97      0.99        37\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      6110\n",
      "   macro avg       0.98      0.94      0.96      6110\n",
      "weighted avg       1.00      1.00      1.00      6110\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5868\n",
      "           1       0.94      0.89      0.91        36\n",
      "           2       0.95      0.92      0.93        38\n",
      "           3       0.99      0.92      0.96       131\n",
      "           4       1.00      0.97      0.99        37\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      6110\n",
      "   macro avg       0.98      0.94      0.96      6110\n",
      "weighted avg       1.00      1.00      1.00      6110\n",
      "\n",
      "Epoch:  6  Loss:  tensor(0.0026, device='cuda:0')   F1 Test Score 0.9576969086397178   F1 Train Score 0.9930007024466476\n",
      "Learning rate:  1e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5868\n",
      "           1       0.94      0.86      0.90        36\n",
      "           2       0.97      0.92      0.95        38\n",
      "           3       0.98      0.93      0.96       131\n",
      "           4       0.97      0.97      0.97        37\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      6110\n",
      "   macro avg       0.97      0.94      0.95      6110\n",
      "weighted avg       1.00      1.00      1.00      6110\n",
      "\n",
      "Epoch:  7  Loss:  tensor(0.0025, device='cuda:0')   F1 Test Score 0.9544578975470668   F1 Train Score 0.9863578668171697\n",
      "Learning rate:  1e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5868\n",
      "           1       0.91      0.89      0.90        36\n",
      "           2       0.90      0.92      0.91        38\n",
      "           3       0.98      0.89      0.94       131\n",
      "           4       1.00      0.97      0.99        37\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      6110\n",
      "   macro avg       0.96      0.93      0.95      6110\n",
      "weighted avg       1.00      1.00      1.00      6110\n",
      "\n",
      "Epoch:  8  Loss:  tensor(0.0017, device='cuda:0')   F1 Test Score 0.9461005323474948   F1 Train Score 0.9945796184954554\n",
      "Learning rate:  1e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5868\n",
      "           1       0.94      0.92      0.93        36\n",
      "           2       0.83      0.92      0.88        38\n",
      "           3       0.88      0.96      0.92       131\n",
      "           4       0.95      0.97      0.96        37\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      6110\n",
      "   macro avg       0.92      0.95      0.94      6110\n",
      "weighted avg       0.99      0.99      0.99      6110\n",
      "\n",
      "Epoch:  9  Loss:  tensor(0.0015, device='cuda:0')   F1 Test Score 0.9355908996399795   F1 Train Score 0.9893532535316748\n",
      "Learning rate:  1e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-ec6db184c71b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mtrue_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mbert_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbert_feature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbert_feature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbert_feature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mpred_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-679170ee11bb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, bert_batch)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0msegment_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_mask\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# dummy segment IDs, since we only have one sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mbert_last_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;31m# select the states representing each token start, for each instance in the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             bert_token_reprs = [\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-pretrained-BERT/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    627\u001b[0m         encoded_layers = self.encoder(embedding_output,\n\u001b[1;32m    628\u001b[0m                                       \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m                                       output_all_encoded_layers=output_all_encoded_layers)\n\u001b[0m\u001b[1;32m    630\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-pretrained-BERT/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mall_encoder_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_module\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0mall_encoder_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-pretrained-BERT/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-pretrained-BERT/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, attention_mask)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mself_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-pretrained-BERT/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mmixed_value_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mquery_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixed_query_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixed_key_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixed_value_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-pretrained-BERT/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mtranspose_for_scores\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mnew_x_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_attention_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_x_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "\n",
    "\n",
    "#weight=torch.tensor(list(cc)).cuda()\n",
    "cross_entropy = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(encoder.parameters(), lr =  1e-5,weight_decay=0.0)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10)\n",
    "\n",
    "encoder.zero_grad()\n",
    "epochs = 100\n",
    "score = 0\n",
    "\n",
    "\n",
    "train_size = len(XT)\n",
    "loss_plot=[]\n",
    "for iij in range(epochs):\n",
    "    encoder.train()\n",
    "    epoch_loss = 0\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print (\"Learning rate: \", param_group['lr'])\n",
    "    \n",
    "    for j, batch in enumerate(np.random.randint(0,train_size, size=(int(train_size/batch_size),batch_size))):\n",
    "        optimizer.zero_grad()\n",
    "        ytr=[]\n",
    "        ypr=[]\n",
    "\n",
    "        for index in batch:\n",
    "            true_labels=torch.tensor([int(x) for x in list(list(YT)[index])]).long()\n",
    "            \n",
    "            bert_batch=[bert_feature[0][index].view([1,512]),bert_feature[1][index].view([1,512]),bert_feature[2][index].view([1,512])]\n",
    "            pred_logits=encoder.forward(bert_batch)\n",
    "            y_pred=pred_logits.view([pred_logits.size()[1],5])\n",
    "            ytr.append(true_labels.cuda())\n",
    "            ypr.append(y_pred)\n",
    "        yp=torch.cat(ypr, dim=0)\n",
    "        yt=torch.cat(ytr, dim=0).long()\n",
    "        loss = cross_entropy(yp,yt)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss +=loss.data\n",
    "    \n",
    "    loss_plot.append(epoch_loss/float(train_size/batch_size))\n",
    "    scheduler.step(epoch_loss/float(train_size/batch_size))\n",
    "######################################################################################\n",
    "    encoder.eval()\n",
    "    all_pred = []\n",
    "    all_label = []\n",
    "    for index, test_idx in enumerate(XT):\n",
    "\n",
    "        true_labels=torch.tensor([int(x) for x in list(list(YT)[index])]).long()    \n",
    "        bert_batch=[bert_feature[0][index].view([1,512]),bert_feature[1][index].view([1,512]),bert_feature[2][index].view([1,512])]\n",
    "        pred_logits=encoder.forward(bert_batch)\n",
    "        y_pred=pred_logits.view([pred_logits.size()[1],5])\n",
    "\n",
    "        predictions = np.argmax(y_pred.cpu().data.numpy(), axis=1)\n",
    "\n",
    "        all_pred = all_pred + list(predictions)\n",
    "        all_label = all_label + list(true_labels)\n",
    "    f1_train=f1_score(np.array(all_label), np.array(all_pred),average='macro')\n",
    "#     print ('Epoch: ', iij, ' Loss: ', epoch_loss/float(train_size/batch_size),' ','F1 train: ',f1_train)\n",
    "    all_pred = []\n",
    "    all_label = []\n",
    "    for index, test_idx in enumerate(XVAL):\n",
    "\n",
    "        true_labels=torch.tensor([int(x) for x in list(list(YVAL)[index])]).long()    \n",
    "        bert_batch=[bert_feature_val[0][index].view([1,512]),bert_feature_val[1][index].view([1,512]),bert_feature_val[2][index].view([1,512])]\n",
    "        pred_logits=encoder.forward(bert_batch)\n",
    "        y_pred=pred_logits.view([pred_logits.size()[1],5])\n",
    "\n",
    "        predictions = np.argmax(y_pred.cpu().data.numpy(), axis=1)\n",
    "\n",
    "        all_pred = all_pred + list(predictions)\n",
    "        all_label = all_label + list(true_labels)\n",
    "    f1_test=f1_score(np.array(all_label), np.array(all_pred),average='macro')\n",
    "\n",
    "\n",
    "    print(classification_report(np.array(all_label), np.array(all_pred)))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#     scheduler.step(epoch_loss/float(train_size/batch_size))\n",
    "    if score <= f1_test:\n",
    "        print(classification_report(np.array(all_label), np.array(all_pred)))\n",
    "        early_stop_count = 0\n",
    "#         print (\"\\n Score increased from {} to {}\".format(score, f1_test))\n",
    "        score = f1_test\n",
    "\n",
    "        if score > 0.95:\n",
    "            print(classification_report(np.array(all_label), np.array(all_pred)))\n",
    "            torch.save({\n",
    "                'epoch': iij + 1,\n",
    "                'state_dict': encoder.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'model': encoder,\n",
    "                'score': score\n",
    "            }, '/home/raghu/invoice/models/' + 'invoice_bert_withoutW_' + str(iij + 1)+ \"_\" + str(int(score*100)) + '.pt')\n",
    "    else:\n",
    "        early_stop_count = early_stop_count + 1\n",
    "#         print (\"Score decreased. Count: \", early_stop_count)    \n",
    "\n",
    "#     if early_stop_count == 20:\n",
    "#         break\n",
    "    print ('Epoch: ', iij, ' Loss: ', epoch_loss/float(train_size/batch_size),' ','F1 Test Score',f1_test,' ','F1 Train Score',f1_train)\n",
    "#     print (\"---------------------------------------------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_predictions_from_block(text_blocks):\n",
    "    all_pred = []\n",
    "    for index, test_idx in enumerate(text_blocks):   \n",
    "        bert_batch=[bert_feature_val[0][index].view([1,512]).cpu(),bert_feature_val[1][index].view([1,512]).cpu(),bert_feature_val[2][index].view([1,512]).cpu()]\n",
    "        pred_logits=encoder.forward(bert_batch)\n",
    "        y_pred=pred_logits.view([pred_logits.size()[1],5])\n",
    "\n",
    "        predictions = np.argmax(y_pred.cpu().data.numpy(), axis=1)\n",
    "        all_pred = all_pred + list(predictions)\n",
    "    return all_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.load('/home/raghu/invoice/models/invoice_bert_withoutW_7_95.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = x['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XVAL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7b5b1433c606>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mall_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mall_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrue_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'XVAL' is not defined"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "all_pred = []\n",
    "all_label = []\n",
    "for index, test_idx in enumerate(XVAL):\n",
    "\n",
    "    true_labels=torch.tensor([int(x) for x in list(list(YVAL)[index])]).long()    \n",
    "    bert_batch=[bert_feature_val[0][index].view([1,512]),bert_feature_val[1][index].view([1,512]),bert_feature_val[2][index].view([1,512])]\n",
    "    pred_logits=encoder.forward(bert_batch)\n",
    "    y_pred=pred_logits.view([pred_logits.size()[1],5])\n",
    "\n",
    "    predictions = np.argmax(y_pred.cpu().data.numpy(), axis=1)\n",
    "\n",
    "    all_pred = all_pred + list(predictions)\n",
    "    all_label = all_label + list(true_labels)\n",
    "f1_test=f1_score(np.array(all_label), np.array(all_pred),average='macro')\n",
    "\n",
    "\n",
    "print(classification_report(np.array(all_label), np.array(all_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9576969086397178"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raghu/venv/lib/python3.6/site-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type SequenceTagger. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save({\n",
    "    'epoch': iij + 1,\n",
    "    'state_dict': encoder.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'model': encoder,\n",
    "    'score': score\n",
    "}, '/home/raghu/invoice/models/' + 'invoice_all_withW_bert_' + str(iij + 1)+ \"_\" + str(int(f1_test*100)) + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder,'/home/raghu/invoice_bert_95.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
